# 30 Days of AI Engineering & Data Science

A comprehensive 30-day journey mastering AI Engineering (GenAI/LLMs) and Data Science through hands-on projects.

## Overview

This repository documents my intensive 30-day challenge to build and polish skills in:
- **Data Science**: Data wrangling, visualization, classical ML
- **AI Engineering**: Deep Learning, LLMs, RAG systems, fine-tuning
- **MLOps**: Model deployment, APIs, productionization

## Daily Progress

### Week 1: Foundation & Classical ML
- **Day 1**: Data Wrangling Mastery - Cleaning Google Play Store data
- **Day 2**: Data Visualization - Exploratory analysis and storytelling
- **Day 3**: Regression - Predicting app ratings
- **Day 4**: Classification - Predicting free vs paid apps
- **Day 5**: ML Engineering - Building FastAPI model service with web interface
- **Day 6**: SQL Deep Dive - Advanced analysis of app data
- **Day 7**: Review & Portfolio Building (Current)

### Week 2: Deep Learning Fundamentals (Upcoming)
- Neural Networks, PyTorch, Transformers, Hugging Face

### Week 3: Advanced AI Projects (Upcoming)  
- RAG systems, Fine-tuning, Domain-specific chatbots

### Week 4: Production & Deployment (Upcoming)
- MLOps, Cloud deployment, Full-stack applications

## Featured Projects

### 1. App Type Prediction API
**Technologies**: Python, FastAPI, Scikit-learn, Bootstrap
- Built ML model to predict app pricing type (Free/Paid)
- Created production-ready API with automatic documentation
- Designed responsive web interface for predictions
- **Live Demo**: [Localhost API](http://127.0.0.1:8000)

### 2. Google Play Store Analysis
**Technologies**: Pandas, SQL, Matplotlib, Seaborn
- Cleaned and analyzed 10,000+ app dataset
- Created comprehensive visualizations and insights
- Performed advanced SQL analysis for business insights

### 3. Data Engineering Pipeline
**Technologies**: SQLite, Python, Data Wrangling
- Built complete data processing pipeline from raw data to insights
- Implemented robust data cleaning and validation
- Created reproducible analysis workflows

## Technical Skills

### Data Science
- **Data Wrangling**: Pandas, NumPy, Data cleaning, Feature engineering
- **Visualization**: Matplotlib, Seaborn, Storytelling with data
- **Machine Learning**: Scikit-learn, Regression, Classification, Evaluation metrics
- **SQL**: Advanced queries, Window functions, CTEs, Performance optimization

### AI Engineering  
- **Web Frameworks**: FastAPI, RESTful APIs, Automatic documentation
- **Frontend**: HTML/CSS, JavaScript, Bootstrap, Responsive design
- **MLOps**: Model serialization, API development, Error handling

### Tools & Platforms
- **Version Control**: Git, GitHub
- **Development**: Python, Jupyter Notebooks, VS Code
- **Database**: SQLite, Database design

## Key Achievements

- Built 5+ complete end-to-end projects in 7 days
- Mastered data cleaning with real-world messy data
- Created production-ready ML API with web interface
- Performed advanced SQL analysis on complex datasets
- Developed strong documentation and reproducibility practices

## Learning Outcomes

### Technical Skills
- End-to-end data science project execution
- Production ML model deployment
- Advanced SQL for data analysis
- API development and web integration

### Professional Skills
- Project documentation and presentation
- Problem-solving with real-world data challenges
- Time management and consistent learning habits
- Portfolio development and showcase creation

## Repository Structure

```
30DaysOfAIDS/
│
├── Day1_DataWrangling/          # Data cleaning & preprocessing
├── Day2_Visualization/          # EDA & storytelling
├── Day3_Regression/             # Rating prediction model
├── Day4_Classification/         # App type classification  
├── Day5_Model_API/              # FastAPI deployment
├── Day6_SQL_Dive/               # Advanced SQL analysis
├── Day7_Review_Portfolio/       # Documentation & review
└── README.md                    # This file
```

## How to Run Projects

Each day has specific instructions. Generally:

1. Navigate to the day's folder
2. Check the README for dependencies
3. Run the main Python scripts or Jupyter notebooks
4. Explore the results and documentation

## Next Steps

- Week 2: Deep Learning with PyTorch and Transformers
- Week 3: Building RAG systems and fine-tuning LLMs  
- Week 4: MLOps and cloud deployment

## Blog Post

[Portfolio](./Day7_Review_Portfolio/blog_week1_review.md) about this 30-day challenge.

## Connect

- **LinkedIn**: [Azfar Murtaza](https://www.linkedin.com/in/azfar-murtaza-0b2994303/)
- **GitHub**: [azfar3](https://github.com/azfar3)
- **Portfolio**: [Portfolio](./Day7_Review_Portfolio/portfolio.html)
- **Email**: azfarmurtaza5@gmail.com

---

*This journey is documented day-by-day with complete code, explanations, and lessons learned.*